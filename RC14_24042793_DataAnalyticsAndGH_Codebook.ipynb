{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e526f20-77b4-4f89-901f-98bdb8896efd",
   "metadata": {},
   "source": [
    "# PART A: DATA VISUALISATION AND ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18887706-9269-4056-96d6-b3762fc14eee",
   "metadata": {},
   "source": [
    "### 1. Check Python Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3add3fe0-cb1c-4d10-80e6-e54d2f4d052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check python environment \n",
    "import sys\n",
    "import platform\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "import os\n",
    "\n",
    "# Basic Python information\n",
    "print(f\"Python version: {platform.python_version()}\")\n",
    "print(f\"Python implementation: {platform.python_implementation()}\")\n",
    "print(f\"Python path: {sys.executable}\")\n",
    "print(f\"Python location: {sys.prefix}\")\n",
    "\n",
    "# Operating system information\n",
    "print(f\"\\nOS: {platform.system()} {platform.release()}\")\n",
    "print(f\"Architecture: {platform.machine()}\")\n",
    "\n",
    "# Environment variables\n",
    "print(\"\\nRelevant environment variables:\")\n",
    "for var in ['PATH', 'PYTHONPATH', 'CONDA_PREFIX', 'VIRTUAL_ENV']:\n",
    "    if var in os.environ:\n",
    "        print(f\"{var}: {os.environ[var]}\")\n",
    "\n",
    "# Check if running in Conda environment\n",
    "in_conda = os.environ.get('CONDA_PREFIX') is not None\n",
    "print(f\"\\nRunning in Conda environment: {in_conda}\")\n",
    "\n",
    "if in_conda:\n",
    "    # Get conda info\n",
    "    print(\"\\nConda information:\")\n",
    "    try:\n",
    "        conda_info = subprocess.check_output(['conda', 'info'], text=True)\n",
    "        print(conda_info)\n",
    "    except:\n",
    "        print(\"Could not retrieve conda info\")\n",
    "\n",
    "# List installed packages\n",
    "print(\"\\nInstalled packages:\")\n",
    "installed_packages = sorted([f\"{pkg.key}=={pkg.version}\" for pkg in pkg_resources.working_set])\n",
    "for package in installed_packages[:10]:  # Show first 10 packages\n",
    "    print(package)\n",
    "print(f\"... and {len(installed_packages) - 10} more packages\")\n",
    "\n",
    "# Check for virtual environment\n",
    "venv = os.environ.get('VIRTUAL_ENV')\n",
    "if venv:\n",
    "    print(f\"\\nVirtual environment: {venv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9af10d-d73f-40f9-b966-e22cad4c84bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python version: 3.12.4\n",
    "# Python implementation: CPython\n",
    "# Python path: C:\\Users\\haojun\\anaconda3\\python.exe\n",
    "# Python location: C:\\Users\\haojun\\anaconda3\n",
    "\n",
    "# OS: Windows 11\n",
    "# Architecture: AMD64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17697030-0157-43e4-9fc1-c63c2318cc8c",
   "metadata": {},
   "source": [
    "### 2.1 Data Scraping (Selenium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae15950c-b49c-47d8-8df2-25f51f041f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMDb：Search the locations of famous film and television productions\n",
    "https://www.imdb.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d49ed7a-7181-4635-8382-76d4223d03a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# “London, England” as searching Keyword\n",
    "URL:https://www.imdb.com/find/?s=kw&q=London%2C%20England&ref_=nv_sr_sm\n",
    "selenium - Data Scraping(XPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9314df3-3bbd-43e9-8522-8218b267c37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaf3a74-7616-4c75-ad86-d5b61228762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "chrome_options= Options()\n",
    "chrome_options.add_argument(\"--disable-search-engine-choice-screen\")\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "\n",
    "driver.get('https://google.com')\n",
    "#Chrome opens with an additional alert message on top\n",
    "#driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67d6b8b-dfa8-4917-9316-14bb2aecc7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(driver.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7625afa-9112-4d91-b49a-c6b0e4029104",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(driver.current_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7371987-2ebf-49f7-ac43-01ae8b240806",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.save_screenshot('screenshot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06647c8c-121e-4099-b32a-de4e7767bfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#headless mode\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless=new\")\n",
    "options.add_argument(\"--disable-search-engine-choice-screen\")\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "driver.get(\"https://www.nintendo.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a09cb05-ac8a-4432-bc44-3a2bb2a6cfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(driver.current_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcc2576-ae7e-4e4f-9bc9-776837f6a008",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f59bf3-811a-4990-a28e-8ed57b121c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from time import sleep\n",
    "\n",
    "# Configure Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-search-engine-choice-screen\")\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# IMDb Search result URL (including keywords London, England)\n",
    "url = \"https://www.imdb.com/search/title/?keywords=london-england&explore=keywords&sort=moviemeter,desc\"\n",
    "driver.get(url)\n",
    "\n",
    "# Create a list to store data\n",
    "titles_list = []\n",
    "years_list = []\n",
    "ratings_list = []\n",
    "types_list = []\n",
    "links_list = []\n",
    "contents_list = []\n",
    "\n",
    "# Defining data extraction functions\n",
    "def extract_page_data(driver):\n",
    "    # Get the title, year, rating, genre, link and synopsis of a movie or TV show\n",
    "    titles = driver.find_elements(By.CSS_SELECTOR, \".lister-item-header a\")\n",
    "    years = driver.find_elements(By.CSS_SELECTOR, \".lister-item-year\")\n",
    "    ratings = driver.find_elements(By.CSS_SELECTOR, \".ratings-imdb-rating strong\")\n",
    "    types = driver.find_elements(By.CSS_SELECTOR, \".genre\")\n",
    "    contents = driver.find_elements(By.CSS_SELECTOR, \".ratings-bar + .text-muted\")  # Select profile\n",
    "    \n",
    "    # Extract information one by one and store it in the corresponding list\n",
    "    for i in range(len(titles)):\n",
    "        titles_list.append(titles[i].text)\n",
    "        years_list.append(years[i].text if i < len(years) else \"N/A\")  # Handling Possible Missing Years\n",
    "        ratings_list.append(ratings[i].text if i < len(ratings) else \"N/A\")  # Dealing with possible missing ratings\n",
    "        types_list.append(types[i].text.strip() if i < len(types) else \"N/A\")  # Remove leading and trailing spaces\n",
    "        links_list.append(titles[i].get_attribute(\"href\"))\n",
    "        contents_list.append(contents[i].text.strip() if i < len(contents) else \"N/A\")  # Remove leading and trailing spaces\n",
    "\n",
    "# Loop through the extracted data and click the \"50 More\" button\n",
    "for page_num in range(3):  # Suppose you click the \"50 More\" button 3 times\n",
    "    extract_page_data(driver)\n",
    "    \n",
    "    try:\n",
    "        # Waiting for and locating the IMDb \"50 More\" button, using minimal XPath\n",
    "        more_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//*[@id='__next']//button[contains('50 More')]\"))\n",
    "        )\n",
    "        more_button.click()\n",
    "        sleep(2)  # Waiting for new content to load\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to click the '50 More' button: {e}\")\n",
    "        break\n",
    "\n",
    "# Close browser\n",
    "driver.quit()\n",
    "\n",
    "# Print results\n",
    "print(\"Title list:\", titles_list)\n",
    "print(\"Year list:\", years_list)\n",
    "print(\"Rating list:\", ratings_list)\n",
    "print(\"Type list:\", types_list)\n",
    "print(\"Link list:\", links_list)\n",
    "print(\"Introduction list:\", contents_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "298f22ba-e666-465d-b657-47a5575019d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wikipedia：https://en.wikipedia.org/wiki/Category:Films_shot_in_London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cf918dc-87a2-44b1-ba86-2b09c50e8e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combination with other resources \n",
    "manually or semi-automatically supplement information \n",
    "such as the title of the film and television work, appearing characters, shooting locations and plot summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d2e585c-0d16-4853-99bd-ffb13a5a68ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Python's geopy library to convert addresses to coordinates (latitude and longitude)\n",
    "# Combine the Pandas library to handle Excel files\n",
    "# Get the coordinates of the address and then save the result back to the Excel file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e97f6e7-7bcd-4fb0-9c0b-7e6ee3233e91",
   "metadata": {},
   "source": [
    "### 2.2 Data Scraping (Goodle Maps API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "790fc1a8-a112-4f93-989e-f8f30dce044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Maps API：https://developers.google.com/maps/documentation/places/web-service?hl=zh-cn\n",
    "API KEY:AIzaSyDh3FxuW05_D002oA-rrY378pQ7BnaKbhY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b0ccf4-aff7-4c0b-81f8-8ba3919060d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440ffb9b-3d9c-4329-bdcd-fd3463fd8aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Replace with your API key\n",
    "API_KEY = 'AIzaSyDh3FxuW05_D002oA-rrY378pQ7BnaKbhY'\n",
    "\n",
    "def get_coordinates(address):\n",
    "    # Google Places API Geocoding URL\n",
    "    url = f'https://maps.googleapis.com/maps/api/geocode/json?address={address}&key={API_KEY}'\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data['status'] == 'OK':\n",
    "            latitude = data['results'][0]['geometry']['location']['lat']\n",
    "            longitude = data['results'][0]['geometry']['location']['lng']\n",
    "            return latitude, longitude\n",
    "        else:\n",
    "            print(f\"Error: {data['status']} for address: {address}\")\n",
    "            return None, None\n",
    "    else:\n",
    "        print(f\"HTTP Error: {response.status_code} for address: {address}\")\n",
    "        return None, None\n",
    "\n",
    "# Read Excel file\n",
    "df = pd.read_excel('places.xlsx')  # Replace with your Excel file name\n",
    "\n",
    "# Assuming the address is in the 'Address' column\n",
    "df['Latitude'] = None\n",
    "df['Longitude'] = None\n",
    "\n",
    "# Get coordinates\n",
    "for index, row in df.iterrows():\n",
    "    address = row['Address']  # Replace with your address column name\n",
    "    latitude, longitude = get_coordinates(address)\n",
    "    df.at[index, 'Latitude'] = latitude\n",
    "    df.at[index, 'Longitude'] = longitude\n",
    "    print(f\"Processed: {address} -> ({latitude}, {longitude})\")\n",
    "    time.sleep(1)  # Add a delay to avoid too fast requests\n",
    "\n",
    "# Save the results to a new Excel file\n",
    "df.to_excel('output_file.xlsx', index=False)  # Replace with the output file name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc49742-1beb-48c7-bbb6-d5c0999d404a",
   "metadata": {},
   "source": [
    "### 2.3 Data Scraping (Goodle Places API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d4dd24-98ef-4db9-9c02-44f3d00cbcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d11cb25-b3d5-4006-bef0-fda958fabb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "chrome_options= Options()\n",
    "chrome_options.add_argument(\"--disable-search-engine-choice-screen\")\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "\n",
    "driver.get('https://google.com')\n",
    "#Chrome opens with an additional alert message on top\n",
    "#driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d998299-d30e-4017-b416-733c0566560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(driver.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1372ce0b-a2a5-44a9-8b78-f040bcfeb982",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(driver.current_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b32d48-99d8-4147-a445-65ba6bef544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.save_screenshot('screenshot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62fb7f0-a78c-4b13-a521-14dcacf602b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#headless mode\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless=new\")\n",
    "options.add_argument(\"--disable-search-engine-choice-screen\")\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "driver.get(\"https://www.nintendo.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f1ddfb-0426-4f48-ba01-76796e7b8333",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(driver.current_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67be8db6-3970-482c-8d2b-7c81b1cb16b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ad6fc2-cf2f-493b-b4cd-96046c384bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Your Google Places API key\n",
    "API_KEY = 'AIzaSyDh3FxuW05_D002oA-rrY378pQ7BnaKbhY'\n",
    "\n",
    "# London's coordinates (latitude, longitude)\n",
    "location = '51.5074,-0.1278'  \n",
    "radius = 1000000  # Search radius in meters\n",
    "keywords = ['film production location', 'anime production location', 'game production location']\n",
    "\n",
    "# Initialize a list to store search results\n",
    "locations_data = []\n",
    "\n",
    "# Google Places API base URL\n",
    "base_url = 'https://maps.googleapis.com/maps/api/place/nearbysearch/json'\n",
    "\n",
    "# Define search function\n",
    "def search_places(keyword):\n",
    "    params = {\n",
    "        'location': location,\n",
    "        'radius': radius,\n",
    "        'keyword': keyword,\n",
    "        'key': API_KEY\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    results = response.json().get('results', [])\n",
    "    \n",
    "    # Processing the returned location data\n",
    "    for place in results:\n",
    "        place_info = {\n",
    "            'Name': place.get('name'),\n",
    "            'Address': place.get('vicinity'),\n",
    "            'Latitude': place['geometry']['location']['lat'],\n",
    "            'Longitude': place['geometry']['location']['lng'],\n",
    "            'Type': keyword\n",
    "        }\n",
    "        locations_data.append(place_info)\n",
    "\n",
    "# Use different keywords to search for places\n",
    "for keyword in keywords:\n",
    "    search_places(keyword)\n",
    "    time.sleep(1)  # Delay to avoid triggering API rate limits\n",
    "\n",
    "# Save the data to a CSV file\n",
    "df = pd.DataFrame(locations_data)\n",
    "df.to_csv('london_production_locations.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Location information has been successfully exported to 'london_production_locations.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3890e679-6043-4634-8bdf-ad7c525151e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading CSV Files\n",
    "df = pd.read_csv('london_landmarks.csv')\n",
    "\n",
    "# View the previous rows of data\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba03561a-5448-4ff4-bdde-f5e66898f2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View basic information about the data\n",
    "print(df.info())\n",
    "\n",
    "# View unique landmark types\n",
    "print(df['Type'].unique())\n",
    "\n",
    "# For example, filter out landmarks related to anime\n",
    "anime_landmarks = df[df['Type'] == 'anime landmark']\n",
    "print(anime_landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf771c1-fec3-4c3e-ad23-1845156d67a5",
   "metadata": {},
   "source": [
    "### 3. Data Analysing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38a6a849-1c5f-44cc-b7f2-7d3d449efe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WGS 84（World Geodetic System 1984） - EPSG:27700/ British National Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08cdb4f-7bda-409a-9a44-aede1677fb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyproj import Transformer\n",
    "\n",
    "# Set up the converter\n",
    "transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:27700\")\n",
    "\n",
    "# Read CSV file\n",
    "file_path = r'E:\\MyDocuments\\UCL\\RC14\\TERM1\\Tutorial\\CINEMAP\\7ghdatabase.csv'  # Modify the path according to your file location\n",
    "output_file = r'E:\\MyDocuments\\UCL\\RC14\\TERM1\\Tutorial\\CINEMAP\\8-3DVisualization.csv'  # Output file path\n",
    "\n",
    "# Assume the CSV file has two columns: Latitude and Longitude\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Check if necessary columns are included\n",
    "if 'Latitude' in data.columns and 'Longitude' in data.columns:\n",
    "    # Batch conversion\n",
    "    def transform_coordinates(row):\n",
    "        east, north = transformer.transform(row['Latitude'], row['Longitude'])\n",
    "        return pd.Series({'East': east, 'North': north})\n",
    "    \n",
    "    # Apply the transformation and add the result to a new column\n",
    "    data[['East', 'North']] = data.apply(transform_coordinates, axis=1)\n",
    "\n",
    "    # Save to a new CSV file\n",
    "    data.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "    print(f\"Conversion complete! Results saved to {output_file}\")\n",
    "else:\n",
    "    print(\"The input CSV file must contain 'Latitude' and 'Longitude' columns!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4462b223-65b8-4174-87b8-3f539e2bae07",
   "metadata": {},
   "source": [
    "### 3.1 LocationMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7171b98b-4d07-40af-bcc9-6c3e66fe4233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Postcode of Points\n",
    "# Use Python's pandas library to add type,category, and area columns\n",
    "Typemap\n",
    "Categorymap\n",
    "Areamap\n",
    "# Symbology\n",
    "# Use Python's pandas library to add a column and count the number of times each location is used in an Excel file\n",
    "Location_Popularitymap\n",
    "# Symbology\n",
    "# Count the number of points in each lsoa according to the lsoa where the point is located\n",
    "LSOA_Popularitymap\n",
    "# Symbology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96725ed9-b648-4084-9cd9-f3b75a505d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read CSV\n",
    "file_path1 = r'E:\\MyDocuments\\UCL\\RC14\\TERM1\\Tutorial\\CINEMAP\\5losaborough_file.csv'  # Modify the path according to your file location\n",
    "data1 = pd.read_csv(file_path1)\n",
    "\n",
    "file_path2 = r'E:\\MyDocuments\\UCL\\RC14\\TERM1\\Tutorial\\CINEMAP\\data set\\公共交通可达性水平LSOA2011 AvPTAI2015.csv'  # Modify the path according to your file location\n",
    "data2 = pd.read_csv(file_path2)\n",
    "\n",
    "# Assume that the column name of LSOA code in both files is 'LSOA code'\n",
    "# If the column name is different, you need to adjust it according to the actual situation\n",
    "merged_data = pd.merge(data1, data2, on='LSOA code', how='inner')\n",
    "\n",
    "# Export matching results to a new CSV file\n",
    "merged_data.to_csv('matched_LSOA_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8761dd4-f19e-4d52-b9dc-d45501f0f736",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5be741b-5328-4097-bd22-559e8dede347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read Excel file\n",
    "file_path = 'output_file.xlsx'  # Replace with your Excel file path\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Create a new column 'Category' to store the classification results\n",
    "def categorize_location(Name):\n",
    "    # Keyword classification (can be adjusted as needed)\n",
    "    if any(keyword in Name.lower() for keyword in ['tower', 'castle', 'palace', 'abbey']):\n",
    "        return 'Historical Building'\n",
    "    elif any(keyword in Name.lower() for keyword in ['park', 'garden', 'square']):\n",
    "        return 'Park or Outdoor'\n",
    "    elif any(keyword in Name.lower() for keyword in ['museum', 'gallery']):\n",
    "        return 'Museum or Gallery'\n",
    "    elif any(keyword in Name.lower() for keyword in ['street', 'road', 'avenue', 'square']):\n",
    "        return 'Street or Square'\n",
    "    elif any(keyword in Name.lower() for keyword in ['bridge', 'river']):\n",
    "        return 'Bridge or River'\n",
    "    elif any(keyword in Name.lower() for keyword in ['station', 'terminal']):\n",
    "        return 'Station'\n",
    "    elif any(keyword in Name.lower() for keyword in ['mall', 'market', 'shop', 'shopping', 'center']):\n",
    "        return 'Commercial'\n",
    "    elif any(keyword in Name.lower() for keyword in ['school', 'university', 'college', 'academy']):\n",
    "        return 'School'\n",
    "    elif any(keyword in Name.lower() for keyword in ['city hall', 'government', 'council', 'office']):\n",
    "        return 'Government'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Apply classification function\n",
    "df['Category'] = df['Name'].apply(categorize_location)\n",
    "\n",
    "# Save the classified data to a new Excel file\n",
    "output_path = 'classified_locations.xlsx'\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"Classification completed, results saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915e17b0-8d22-4bda-8d9e-81f535b79e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read Excel file\n",
    "file_path = 'classified_locations.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# View column names\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d029674-ba5e-4d25-9895-fefc7f95f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Excel file\n",
    "file_path = 'classified_locations.xlsx'  # Replace with your file path\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Define classification function\n",
    "def classify_area(postcode):\n",
    "    if postcode.startswith(('EC', 'WC', 'E1', 'W1', 'SW1')):\n",
    "        return 'Central London'\n",
    "    elif postcode.startswith('E'):\n",
    "        return 'East London'\n",
    "    elif postcode.startswith('W'):\n",
    "        return 'West London'\n",
    "    elif postcode.startswith('N'):\n",
    "        return 'North London'\n",
    "    elif postcode.startswith('SE'):\n",
    "        return 'South London'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "# Create a new categorical column\n",
    "df['Area'] = df['Postcode'].apply(classify_area)\n",
    "\n",
    "# Save the results to a new Excel file\n",
    "output_file_path = 'classified_locations.xlsx'  # Output file path\n",
    "df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"Classification completed, results saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476ed61f-6b0f-4d3c-9365-3d866ff20a41",
   "metadata": {},
   "source": [
    "### 3.2 Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9e9693-6fcc-41e4-9874-64600d2356e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read Excel file\n",
    "file_path = 'classified_locations.xlsx'  # Replace with your file path\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Count the number of times each location was used\n",
    "location_counts = df['Name'].value_counts()  # Assume 'Location' is the name of the column storing the location names\n",
    "\n",
    "# Add the times to the original data frame\n",
    "df['Usage Count'] = df['Name'].map(location_counts)\n",
    "\n",
    "# Save the updated data frame back to the Excel file\n",
    "output_file_path = 'updated_file.xlsx'  # Replace with the path of the file you want to save\n",
    "df.to_excel(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e33cf2-1aab-4fd4-a888-647ba6b50f32",
   "metadata": {},
   "source": [
    "### 3.3 Dynamic Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b63d4e-884e-43c3-ad22-a51683467420",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979f1173-bf7b-48f9-bdab-396a2d8d381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "# Create a map center of London\n",
    "london_map = folium.Map(location=[51.5074, -0.1278], zoom_start=12)\n",
    "london_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80c0a41a-736c-41a8-80af-779fd594c17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "# Create a map center of London\n",
    "london_map = folium.Map(location=[51.5074, -0.1278], zoom_start=12)\n",
    "\n",
    "# Add a placemark location to the map\n",
    "for _, row in df.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[row['Latitude'], row['Longitude']],\n",
    "        popup=f\"{row['Name']} ({row['Type']})\",\n",
    "        tooltip=row['Address']\n",
    "    ).add_to(london_map)\n",
    "\n",
    "# Show map\n",
    "london_map.save('london_landmarks_map.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938b5942-b686-4bf0-9fdd-41f3c945d4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered data as a new CSV file\n",
    "anime_landmarks.to_csv('london_anime_landmarks.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"Data has been exported to 'london_anime_landmarks.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18755813-2782-4e5a-b1cc-23ed9f1ff895",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())  # Print the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a083d985-dd35-4e00-a2de-12964e332b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "# Create a map of London\n",
    "london_map = folium.Map(location=[51.5074, -0.1278], zoom_start=12)\n",
    "london_map  # Display maps directly in Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2750525-b622-41a1-9576-4a7b7c15ad10",
   "metadata": {},
   "source": [
    "### 3.4 Classification Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a28af7-2f3f-427b-b4e7-79c41b1d6fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification scatter plot: Use Seaborn's stripplot or swarmplot to show the distribution trend of different types of movies on landmarks\n",
    "·Which types of movies prefer certain specific landmarks?\n",
    "·Do different movie types have common landmark selection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82ed291-1d4c-4ff0-8223-c58b7c768e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example of absolute path\n",
    "file_path = r'E:\\MyDocuments\\UCL\\RC14\\TERM1\\Tutorial\\CINEMAP\\4updated_file.csv'  # Modify the path according to your file location\n",
    "data = pd.read_csv(file_path)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130b3177-3f99-4614-ac0d-6113d0c5d16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Make sure the chart is displayed in JupyterLab\n",
    "%matplotlib inline\n",
    "\n",
    "# Read CSV file\n",
    "file_path = r'E:\\MyDocuments\\UCL\\RC14\\TERM1\\Tutorial\\CINEMAP\\4updated_file.csv' # Modify the path according to your file location\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming each movie genre consists of multiple words separated by commas, first split these words into separate lines\n",
    "data_expanded = data.set_index(['Name'])['Genre'].str.split(',', expand=True).stack().reset_index(level=1, drop=True).to_frame('Genre')\n",
    "\n",
    "# Remove extra spaces\n",
    "data_expanded['Genre'] = data_expanded['Genre'].str.strip()\n",
    "\n",
    "# Count the number of times each landmark appears in each movie genre\n",
    "landmark_counts = data_expanded.groupby(['Genre', 'Name']).size().reset_index(name='count')\n",
    "\n",
    "# Select Color Map: Adjust colors based on number of occurrences\n",
    "norm = plt.Normalize(landmark_counts['count'].min(), landmark_counts['count'].max()) # Create normalization\n",
    "cmap = plt.cm.viridis # Use Viridis color map\n",
    "\n",
    "# Create a drawing\n",
    "plt.figure(figsize=(40, 40))\n",
    "\n",
    "# Create axis object\n",
    "ax = plt.gca()\n",
    "\n",
    "# Use stripplot to plot the distribution trend, increase the size of the points, and change the color according to the number of occurrences\n",
    "sns.stripplot(x='Genre', y='Name', data=landmark_counts, jitter=True, size=10, \n",
    "              hue='count', palette=cmap, ax=ax)\n",
    "\n",
    "# Set the title and label to be larger and bolder\n",
    "plt.title('Distribution of Movie Genres at Landmarks in London', fontsize=30, fontweight='bold', color='white')\n",
    "plt.xlabel('Movie Genre', fontsize=20, fontweight='bold', color='white')\n",
    "plt.ylabel('Landmark Name', fontsize=20, fontweight='bold', color='white')\n",
    "\n",
    "# Set the axis label font size\n",
    "plt.xticks(fontsize=15, fontweight='bold', color='white')\n",
    "plt.yticks(fontsize=15, fontweight='bold', color='white')\n",
    "\n",
    "# Create a ScalarMappable object and set the color bar\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])  # You must call set_array() to display the color bar.\n",
    "\n",
    "# Specifying a colorbar using an ax object\n",
    "fig = plt.gcf()\n",
    "cbar = fig.colorbar(sm, ax=ax)\n",
    "cbar.set_label('Landmark Frequency', fontsize=15, fontweight='bold', color='white')\n",
    "\n",
    "# save image\n",
    "plt.savefig(r'E:\\MyDocuments\\UCL\\RC14\\TERM1\\Tutorial\\CINEMAP\\movie_genre_landmarks.png', \n",
    "            dpi=300,  # Set the resolution, 300 is high resolution\n",
    "            bbox_inches='tight',  # Ensure that the chart content is displayed completely\n",
    "            transparent=False)  # The background is transparent. If you want the background to be black, remove the transparent parameter.\n",
    "\n",
    "# Show chart\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7762e993-5468-4dbf-891b-c2ce9f1de14a",
   "metadata": {},
   "source": [
    "### 3.5 Time Series Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aeb931-2db8-49c0-9761-8274469c8df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Plot\n",
    "Use Matplotlib or Seaborn to plot a time series plot to show the frequency of landmark usage over time.\n",
    "·Which landmarks are used most frequently over time?\n",
    "·Is landmark selection related to urban cultural events at different historical stages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34b6a26-59ab-401b-9578-92adf6daeb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Read CSV file\n",
    "file_path = r'E:\\MyDocuments\\UCL\\RC14\\TERM1\\Tutorial\\CINEMAP\\4updated_file.csv' # Modify the path according to your file location\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Make sure the 'Year' column is of integer type and the 'Name' column is of string type\n",
    "data['Year'] = data['Year'].astype(int)\n",
    "data['Name'] = data['Name'].astype(str)\n",
    "\n",
    "# Calculate the frequency of each landmark in each year\n",
    "frequency = data.groupby(['Year', 'Name']).size().reset_index(name='Frequency')\n",
    "\n",
    "# Use Seaborn to draw a time series graph\n",
    "plt.figure(figsize=(40, 30))\n",
    "sns.lineplot(data=frequency, x='Year', y='Frequency', hue='Name', marker='o', linewidth=3, markersize=10)\n",
    "\n",
    "# Add title and label\n",
    "plt.title('Landmark Usage Frequency Over Time', fontsize=20, fontweight='bold', color='white')\n",
    "plt.xlabel('Year', fontsize=15, fontweight='bold', color='white')\n",
    "plt.ylabel('Frequency', fontsize=15, fontweight='bold', color='white')\n",
    "\n",
    "# Display the chart\n",
    "plt.legend(title='Landmarks', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Adjust the layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the chart\n",
    "plt.savefig(r'E:\\MyDocuments\\UCL\\RC14\\TERM1\\Tutorial\\CINEMAP\\landmark_usage_frequency.png', \n",
    "dpi=300, # Set the resolution, 300 is high resolution\n",
    "bbox_inches='tight', # Ensure that the chart content is fully displayed\n",
    "transparent=False) # Background is transparent. If you want the background to be black, remove the transparent parameter\n",
    "# Display the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84fc25d-afb1-4852-a4f8-43a3a055a133",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1953 - Queen Elizabeth II's Coronation\n",
    "Location: Westminster Abbey\n",
    "#1960s - Swinging London Cultural Revolution\n",
    "Location: Carnaby Street and King's Road\n",
    "#1981 - Brixton Riots\n",
    "Location: Brixton, Brixton High Street​\n",
    "#2012 - London Olympics\n",
    "Location: Olympic Park, Wembley Stadium, Earls Court, especially in Stratford​\n",
    "#2019 - Extinction Rebellion Protests\n",
    "Location: Parliament Square, Oxford Circus\n",
    "#2023 - Chinese New Year Celebrations, London Games Festival, Notting Hill Carnival\n",
    "Location: Chinatown in Soho (Chinese New Year), Royal Festival Hall and Southbank Centre (London Games Festival), Notting Hill (Carnival)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62aa82c3-d6b6-48a9-81a9-a24475303fa2",
   "metadata": {},
   "source": [
    "### 3.6 Time Series Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d059dea7-f0f2-41be-b7be-b9d408abb5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic heat map\n",
    "Use Folium or Geopandas to show the hottest shooting areas over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d713a765-603e-4ad3-bead-39c9f75bc623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from folium.plugins import HeatMapWithTime\n",
    "import folium\n",
    "\n",
    "# Read data\n",
    "file_path = r'E:\\MyDocuments\\UCL\\RC14\\TERM1\\Tutorial\\CINEMAP\\4updated_file.csv' # Modify the path according to your file location\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Make sure the data contains the required columns\n",
    "if not {'Year', 'Name', 'Latitude', 'Longitude'}.issubset(data.columns):\n",
    "raise ValueError(\"Data needs to contain 'Year', 'Name', 'Latitude', 'Longitude' columns\")\n",
    "\n",
    "# Group by year to generate heat map data\n",
    "heat_data = []\n",
    "years = sorted(data['Year'].unique()) # Get all years\n",
    "for year in years:\n",
    "year_data = data[data['Year'] == year]\n",
    "heat_data.append(year_data[['Latitude', 'Longitude']].values.tolist())\n",
    "\n",
    "# Create a Folium map object\n",
    "m = folium.Map(location=[51.509865, -0.118092], zoom_start=11) # Based on the center of London\n",
    "\n",
    "# Add a dynamic heat map\n",
    "HeatMapWithTime(heat_data, radius=10, gradient={0.4: 'blue', 0.65: 'lime', 1: 'red'},\n",
    "index=years, auto_play=True, max_opacity=0.8).add_to(m)\n",
    "\n",
    "# Save as HTML file\n",
    "m.save(r'E:\\MyDocuments\\UCL\\RC14\\TERM1\\Tutorial\\CINEMAP\\dynamic_heatmap.html')\n",
    "print(\"The dynamic heat map has been saved as dynamic_heatmap.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a429fd-fb2f-4106-87be-a617a426399a",
   "metadata": {},
   "source": [
    "### 3.7 K-means Clustering Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9c5536-af5d-434c-8a9c-28c8e1051c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means clustering plot\n",
    "Group landmarks based on popularity, type, or facilities.\n",
    "·Does the distribution of landmarks show some kind of clustering pattern (such as proximity to the city center)?\n",
    "·Is there a relationship between the popularity of landmarks and accessibility to transportation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190d0c58-da55-465c-a752-cc03e82ff9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Read data\n",
    "file_path = r'E:\\MyDocuments\\UCL\\RC14\\TERM1\\Tutorial\\CINEMAP\\4updated_file.csv' # Modify the path according to your file location\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Check column names\n",
    "print(df.columns)\n",
    "\n",
    "# Standardize data\n",
    "features = df[['Latitude', 'Longitude', 'Usage Count']]\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Perform K-means clustering\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "df['Cluster'] = kmeans.fit_predict(scaled_features)\n",
    "\n",
    "# Create a graph and set the background\n",
    "plt.figure(figsize=(40, 40), facecolor='black')\n",
    "\n",
    "# Draw the clustering results\n",
    "scatter = plt.scatter(df['Longitude'], df['Latitude'], c=df['Cluster'], cmap='viridis', \n",
    "marker='o', s=200, edgecolor='none') # Set the point size to 50 and cancel the border\n",
    "\n",
    "# Set the font and color\n",
    "plt.title('K-means Clustering of Landmarks', fontsize=20, color='white')\n",
    "plt.xlabel('Longitude', fontsize=15, color='white')\n",
    "plt.ylabel('Latitude', fontsize=15, color='white')\n",
    "\n",
    "# Set the scale axis\n",
    "plt.xticks(fontsize=12, color='white')\n",
    "plt.yticks(fontsize=12, color='white')\n",
    "\n",
    "# Set the background and grid\n",
    "plt.gca().set_facecolor('black') # Background black\n",
    "plt.grid(True, color='white', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Set the axis gradient color\n",
    "plt.gca().spines['top'].set_color('white')\n",
    "plt.gca().spines['right'].set_color('white')\n",
    "plt.gca().spines['left'].set_color('white')\n",
    "plt.gca().spines['bottom'].set_color('white')\n",
    "\n",
    "# Display the color bar\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label('Cluster', fontsize=12, color='white')\n",
    "cbar.ax.tick_params(labelsize=12, labelcolor='white')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save chart\n",
    "plt.savefig(r'E:\\MyDocuments\\UCL\\RC14\\TERM1\\Tutorial\\CINEMAP\\landmark_clusters.png', \n",
    "dpi=300, # Set resolution, 300 is high resolution\n",
    "bbox_inches='tight', # Ensure that the chart content is fully displayed\n",
    "transparent=False) # Background is transparent, if you want the background to be black, remove the transparent parameter\n",
    "\n",
    "# Display graphics\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42f27d2-9e02-44ff-a19a-6cfd3c13175e",
   "metadata": {},
   "source": [
    "### 3.8 Correlation Heat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8360485-c270-49c4-a8a0-acde02d420e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heat map\n",
    "Discover the potential connection between landmark popularity and other factors (such as transportation, location, density, etc.), and provide decision support for related fields (such as urban planning, tourism, cultural industries, etc.).\n",
    "·Relationship between landmark popularity and transportation accessibility: Landmarks located near transportation hubs may be more likely to attract tourists or film and television shooting.\n",
    "·Relationship between landmark location and popularity: Landmarks in central areas are more popular than those in other areas.\n",
    "·Relationship between transportation accessibility and regional area: Positive correlation, indicating that large areas may have better transportation networks, further supporting people to travel to these areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b2631e-a535-4ee0-917b-9820d99bf985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import chardet\n",
    "file_path = r'E:\\MyDocuments\\UCL\\RC14\\TERM1\\Tutorial\\CINEMAP\\5losa_file.csv' # Modify the path according to your file location\n",
    "\n",
    "# Detect file encoding\n",
    "with open(file_path, 'rb') as f:\n",
    "result = chardet.detect(f.read())\n",
    "\n",
    "print(result)\n",
    "\n",
    "# Load the file using the detected encoding\n",
    "data = pd.read_csv(file_path, encoding=result['encoding'])\n",
    "\n",
    "# 2. Calculate the correlation matrix\n",
    "# If there are non-numeric columns in the data, you can select the numeric columns first\n",
    "numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "correlation_matrix = data[numeric_columns].corr()\n",
    "\n",
    "# Set the background and font color of Seaborn and matplotlib\n",
    "sns.set(style='dark', rc={\"axes.facecolor\": \"black\", \"axes.labelcolor\": \"white\", \"xtick.color\": \"white\", \"ytick.color\": \"white\"})\n",
    "plt.rcParams['figure.facecolor'] = 'black' # Set the background of the entire figure to black\n",
    "plt.rcParams['axes.facecolor'] = 'black' # Set the background of the coordinate axis to black\n",
    "\n",
    "# Draw a heat map\n",
    "plt.figure(figsize=(40, 40)) # Adjust to a suitable size\n",
    "heatmap = sns.heatmap(correlation_matrix, annot=True, cmap='twilight', fmt=\".2f\", vmin=-1, vmax=1,\n",
    "annot_kws={\"size\": 25, \"fontweight\":'bold'}) # Set the number size and color\n",
    "\n",
    "# Set the title and font color\n",
    "plt.title(\"Correlation Heatmap\", fontsize=40, color=\"white\")\n",
    "\n",
    "# Add a colorbar and set its style\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.set_ticks([-1, 0, 1]) # Set the scale value of the color bar\n",
    "cbar.ax.tick_params(labelsize=24, labelcolor=\"white\") # Set the color bar font size and color\n",
    "\n",
    "# Adjust the layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the chart\n",
    "plt.savefig(r'E:\\MyDocuments\\UCL\\RC14\\TERM1\\Tutorial\\CINEMAP\\correlation_heatmap.png', \n",
    "dpi=300, # Set the resolution, 300 is high resolution\n",
    "bbox_inches='tight', # Ensure that the chart content is fully displayed\n",
    "transparent=False) # Background is transparent, if you want the background to be black, remove the transparent parameter\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdde766-9023-4dff-95d7-36a9e4eeda06",
   "metadata": {},
   "source": [
    "# PART C: EXPERIMENTATION WITH MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661fbab4-8e36-4a99-b403-3d9c545b91aa",
   "metadata": {},
   "source": [
    "### 1. Cluster Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42a46fd-8009-4541-82c3-3fce71e63d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "\n",
    "# Set output path\n",
    "output_dir = r\"E:\\MyDocuments\\UCL\\RC14\\TERM1\\Tutorial\\CINEMAP\\seaborn+matpotlib\\Framing Analysis\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Global style settings\n",
    "plt.rcParams['figure.figsize'] = (16.5, 11.7) # A3 horizontal version ratio\n",
    "plt.rcParams['savefig.transparent'] = True\n",
    "plt.rcParams['axes.facecolor'] = 'none' # Transparent coordinate system background\n",
    "plt.rcParams['figure.facecolor'] = 'none' # Transparent background of the figure\n",
    "plt.rcParams['font.size'] = 14 # Global font size (default scale)\n",
    "plt.rcParams['axes.titleweight'] = 'bold' # Bold title\n",
    "plt.rcParams['axes.labelweight'] = 'normal'\n",
    "plt.rcParams['axes.labelsize'] = 16 # Font size of axis labels\n",
    "plt.rcParams['axes.titlecolor'] = 'white' # Title text is white\n",
    "plt.rcParams['xtick.color'] = 'white'\n",
    "plt.rcParams['ytick.color'] = 'white'\n",
    "plt.rcParams['axes.labelcolor'] = 'white' # Axis label color is white\n",
    "plt.rcParams['text.color'] = 'white' # Text color is white\n",
    "plt.rcParams['legend.edgecolor'] = 'white'\n",
    "plt.rcParams['legend.fontsize'] = 14\n",
    "plt.rcParams['axes.edgecolor'] = 'white' # Axis border is white\n",
    "\n",
    "# Read data\n",
    "file_path = r\"E:\\MyDocuments\\UCL\\RC14\\TERM1\\Tutorial\\CINEMAP\\seaborn+matpotlib\\London_LSOA_Film_Analysis_Updated_Realistic.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "numeric_df = df.drop(columns=[\"LSOA_Code\"])\n",
    "\n",
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(numeric_df)\n",
    "scaled_df = pd.DataFrame(data_scaled, columns=numeric_df.columns)\n",
    "\n",
    "# -----------------------\n",
    "# Multiple PCA analysis examples\n",
    "# We show two different PCA projections: PC1 vs PC2, PC1 vs PC3\n",
    "# Finally assume that PC1 vs PC2 is the best solution\n",
    "# -----------------------\n",
    "pca_full = PCA(n_components=3)\n",
    "pca_full.fit(scaled_df)\n",
    "components = pca_full.transform(scaled_df)\n",
    "pca_3df = pd.DataFrame(components, columns=[\"PC1\",\"PC2\",\"PC3\"])\n",
    "\n",
    "# PCA 1: PC1 vs PC2\n",
    "plt.figure()\n",
    "sns.scatterplot(x=\"PC1\", y=\"PC2\", data=pca_3df, alpha=0.7, palette=\"mako\", edgecolor='none')\n",
    "plt.title(\"PCA (PC1 vs PC2) - Chosen Projection\", color='white', fontsize=20, fontweight='bold')\n",
    "plt.xlabel(\"PC1\", fontsize=16, color='white')\n",
    "plt.ylabel(\"PC2\", fontsize=16, color='white')\n",
    "plt.grid(True, color='white', alpha=0.3)\n",
    "# Mark the \"best solution\"\n",
    "plt.text(0.7*max(pca_3df[\"PC1\"]), 0.9*max(pca_3df[\"PC2\"]), \"Best PCA Projection\",\n",
    "         fontsize=16, color='white', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"pca_projection_pc1_pc2.png\"), transparent=True, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# PCA 2: PC1 vs PC3 (for comparison)\n",
    "plt.figure()\n",
    "sns.scatterplot(x=\"PC1\", y=\"PC3\", data=pca_3df, alpha=0.7, palette=\"mako\", edgecolor='none')\n",
    "plt.title(\"PCA (PC1 vs PC3)\", color='white', fontsize=20, fontweight='bold')\n",
    "plt.xlabel(\"PC1\", fontsize=16, color='white')\n",
    "plt.ylabel(\"PC3\", fontsize=16, color='white')\n",
    "plt.grid(True, color='white', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"pca_projection_pc1_pc3.png\"), transparent=True, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# -----------------------\n",
    "# Elbow Method to find the best number of clusters\n",
    "# -----------------------\n",
    "inertia = []\n",
    "k_range = range(2, 7) # For example, try k=2 to k=6\n",
    "for k in k_range:\n",
    "km = KMeans(n_clusters=k, random_state=42)\n",
    "km.fit(scaled_df)\n",
    "inertia.append(km.inertia_)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(k_range, inertia, marker='o', color='white')\n",
    "plt.title(\"Elbow Method for Optimal k\", color='white', fontsize=20, fontweight='bold')\n",
    "plt.xlabel(\"Number of Clusters (k)\", fontsize=16, color='white')\n",
    "plt.ylabel(\"Inertia\", fontsize=16, color='white')\n",
    "plt.grid(True, color='white', alpha=0.3)\n",
    "plt.xticks(k_range)\n",
    "# Assume that k=4 is the best by observing the elbow plot\n",
    "plt.text(4, inertia[k_range.index(4)], \"Chosen k=4\", fontsize=14, color='white', fontweight='bold', \n",
    "horizontalalignment='center', verticalalignment='bottom', bbox=dict(facecolor='none', edgecolor='white'))\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"elbow_method_multiple_k.png\"), transparent=True, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# -----------------------\n",
    "# Multiple K-Means clustering display, comparison of k=3, k=4, k=5\n",
    "# Final choice of k=4\n",
    "# -----------------------\n",
    "for k in [3,4,5]:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    clusters = kmeans.fit_predict(scaled_df)\n",
    "    pca_3df[\"Cluster\"] = clusters\n",
    "\n",
    "    plt.figure()\n",
    "    sns.scatterplot(x=\"PC1\", y=\"PC2\", hue=\"Cluster\", data=pca_3df, alpha=0.7,\n",
    "                    palette=\"mako\", edgecolor='none', legend='full')\n",
    "    if k == 4:\n",
    "        title = f\"K-Means Clustering (k={k}) - Chosen Clusters\"\n",
    "    else:\n",
    "        title = f\"K-Means Clustering (k={k})\"\n",
    "    plt.title(title, color='white', fontsize=20, fontweight='bold')\n",
    "    plt.xlabel(\"PC1\", fontsize=16, color='white')\n",
    "    plt.ylabel(\"PC2\", fontsize=16, color='white')\n",
    "    leg = plt.legend(title=\"Cluster\", facecolor='none', edgecolor='white', labelcolor='white', title_fontsize=16)\n",
    "    for text in leg.get_texts():\n",
    "        text.set_color(\"white\")\n",
    "    plt.grid(True, color='white', alpha=0.3)\n",
    "\n",
    "# If k=4, mark it as the final choice in the figure\n",
    "if k == 4:\n",
    "plt.text(0.8*max(pca_3df[\"PC1\"]), 0.7*max(pca_3df[\"PC2\"]), \"Best K=4 Chosen\",\n",
    "fontsize=16, color='white', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, f\"kmeans_k{k}.png\"), transparent=True, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# -----------------------\n",
    "# Correlation heat map (unchanged)\n",
    "# -----------------------\n",
    "corr = numeric_df.corr()\n",
    "plt.figure()\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"mako\", cbar=True, square=True,\n",
    "            linewidths=0.5, linecolor='white', annot_kws={\"color\":\"white\"}, vmin=-1, vmax=1)\n",
    "plt.title(\"Correlation Heatmap of LSOA Data Features\", color='white', fontsize=20, fontweight='bold')\n",
    "cbar = plt.gca().collections[0].colorbar\n",
    "cbar.ax.yaxis.set_tick_params(color='white')\n",
    "plt.setp(cbar.ax.get_yticklabels(), color='white')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"correlation_heatmap.png\"), transparent=True, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"Analysis completed, all images saved and displayed in Notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57078bcd-6996-4bd7-9c08-74d58159481b",
   "metadata": {},
   "source": [
    "### 2. PIX2PIX Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5285fff-63a9-4d4c-914d-7ea9d6788cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models # add models to the list\n",
    "from torchvision.utils import make_grid\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5da75d-cff1-4ff7-bec1-ba46b039da95",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2266913e-9589-405e-b84b-1220afe14f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444266ef-b02a-4ef0-b58f-89a10d487df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSES FOR NN\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", DEVICE)\n",
    "TRAIN_DIR = \"data/train\"\n",
    "VAL_DIR = \"data/val\"\n",
    "LEARNING_RATE = 2e-4\n",
    "BATCH_SIZE = 17 #Use a number that can divide the total of photos- (here 51/17=3)\n",
    "NUM_WORKERS = 2\n",
    "IMAGE_SIZE = 256\n",
    "CHANNELS_IMG = 3\n",
    "L1_LAMBDA = 100\n",
    "LAMBDA_GP = 10\n",
    "NUM_EPOCHS = 20  #we suggest to start with 5\n",
    "LOAD_MODEL = False #True if you already have some trained weights\n",
    "SAVE_MODEL = True\n",
    "CHECKPOINT_DISC = \"disc.pth.tar\"\n",
    "CHECKPOINT_GEN = \"gen.pth.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d7ad14-049a-4a3f-bf5e-6ba3cae7d8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discriminator model for Pix2Pix\n",
    "\n",
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super(CNNBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 4, stride, 1, bias=False, padding_mode=\"reflect\"),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3, features=[64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(in_channels * 2,features[0],kernel_size=4,stride=2,padding=1,padding_mode=\"reflect\"),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "        layers = []\n",
    "        in_channels = features[0]\n",
    "        for feature in features[1:]:\n",
    "            layers.append(\n",
    "                CNNBlock(in_channels, feature, stride=1 if feature == features[-1] else 2),\n",
    "            )\n",
    "            in_channels = feature\n",
    "\n",
    "        layers.append(\n",
    "            nn.Conv2d(\n",
    "                in_channels, 1, kernel_size=4, stride=1, padding=1, padding_mode=\"reflect\"\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat([x, y], dim=1)\n",
    "        x = self.initial(x)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9286815f-ac20-4ae7-9925-c92378c58195",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator model for Pix2Pix\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, down=True, act=\"relu\", use_dropout=False):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False, padding_mode=\"reflect\")\n",
    "            if down\n",
    "            else nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU() if act == \"relu\" else nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "        self.use_dropout = use_dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.down = down\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return self.dropout(x) if self.use_dropout else x\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels=3, features=64):\n",
    "        super().__init__()\n",
    "        self.initial_down = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, features, 4, 2, 1, padding_mode=\"reflect\"),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.down1 = Block(features, features * 2, down=True, act=\"leaky\", use_dropout=False)\n",
    "        self.down2 = Block(features * 2, features * 4, down=True, act=\"leaky\", use_dropout=False)\n",
    "        self.down3 = Block(features * 4, features * 8, down=True, act=\"leaky\", use_dropout=False)\n",
    "        self.down4 = Block(features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False)\n",
    "        self.down5 = Block(features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False)\n",
    "        self.down6 = Block(features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False)\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(features * 8, features * 8, 4, 2, 1,padding_mode=\"reflect\"), nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.up1 = Block(features * 8, features * 8, down=False, act=\"relu\", use_dropout=True)\n",
    "        self.up2 = Block(features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=True)\n",
    "        self.up3 = Block(features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=True)\n",
    "        self.up4 = Block(features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=False)\n",
    "        self.up5 = Block(features * 8 * 2, features * 4, down=False, act=\"relu\", use_dropout=False)\n",
    "        self.up6 = Block(features * 4 * 2, features * 2, down=False, act=\"relu\", use_dropout=False)\n",
    "        self.up7 = Block(features * 2 * 2, features, down=False, act=\"relu\", use_dropout=False)\n",
    "        self.final_up = nn.Sequential(\n",
    "            nn.ConvTranspose2d(features * 2, in_channels, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        d1 = self.initial_down(x)\n",
    "        d2 = self.down1(d1)\n",
    "        d3 = self.down2(d2)\n",
    "        d4 = self.down3(d3)\n",
    "        d5 = self.down4(d4)\n",
    "        d6 = self.down5(d5)\n",
    "        d7 = self.down6(d6)\n",
    "        bottleneck = self.bottleneck(d7)\n",
    "        up1 = self.up1(bottleneck)\n",
    "        up2 = self.up2(torch.cat([up1, d7], 1))\n",
    "        up3 = self.up3(torch.cat([up2, d6], 1))\n",
    "        up4 = self.up4(torch.cat([up3, d5], 1))\n",
    "        up5 = self.up5(torch.cat([up4, d4], 1))\n",
    "        up6 = self.up6(torch.cat([up5, d3], 1))\n",
    "        up7 = self.up7(torch.cat([up6, d2], 1))\n",
    "        return self.final_up(torch.cat([up7, d1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581f0f8e-a034-4052-ad6f-6fc6cbf3ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train function for Pix2Pix\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def train_fn(disc, gen, loader, opt_disc, opt_gen, l1_loss, bce, g_scaler, d_scaler,):\n",
    "    loop = tqdm(loader, leave=True)\n",
    "\n",
    "    for idx, (x, y) in enumerate(loop):\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "\n",
    "        # Train Discriminator\n",
    "        with torch.cuda.amp.autocast():\n",
    "            y_fake = gen(x)\n",
    "            D_real = disc(x, y)\n",
    "            D_fake = disc(x, y_fake.detach())\n",
    "            D_real_loss = bce(D_real, torch.ones_like(D_real))\n",
    "            D_fake_loss = bce(D_fake, torch.zeros_like(D_fake))\n",
    "            D_loss = (D_real_loss + D_fake_loss) / 2\n",
    "\n",
    "        disc.zero_grad()\n",
    "        d_scaler.scale(D_loss).backward()\n",
    "        d_scaler.step(opt_disc)\n",
    "        d_scaler.update()\n",
    "\n",
    "        # Train generator\n",
    "        with torch.cuda.amp.autocast():\n",
    "            D_fake = disc(x, y_fake)\n",
    "            G_fake_loss = bce(D_fake, torch.ones_like(D_fake))\n",
    "            L1 = l1_loss(y_fake, y) * L1_LAMBDA\n",
    "            G_loss = G_fake_loss + L1\n",
    "\n",
    "        opt_gen.zero_grad()\n",
    "        g_scaler.scale(G_loss).backward()\n",
    "        g_scaler.step(opt_gen)\n",
    "        g_scaler.update()\n",
    "\n",
    "        if idx % 10 == 0:\n",
    "            loop.set_postfix(\n",
    "                D_real=torch.sigmoid(D_real).mean().item(),\n",
    "                D_fake=torch.sigmoid(D_fake).mean().item(),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc8d92-9e50-46cd-9b6b-f7749a623a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils for Pix2Pix\n",
    "\n",
    "def save_some_examples(gen, val_loader, epoch, folder, iteration):\n",
    "  ##ADDITION\n",
    "    y_pred = []\n",
    "  ##\n",
    "    \n",
    "    x, y = next(iter(val_loader))\n",
    "    x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "    gen.eval()\n",
    "    with torch.no_grad():\n",
    "        y_fake = gen(x)\n",
    "        y_fake = y_fake * 0.5 + 0.5  # remove normalization\n",
    "        #print(y_fake.shape)\n",
    "        \n",
    "        ##ADDITION\n",
    "        y_prediction = y_fake.cpu().numpy() #convert pytorch tensor to numpy\n",
    "        y_pred.append(y_prediction)\n",
    "        ##\n",
    "        \n",
    "        save_image(y_fake, folder + f\"/y_gen_{epoch}_{iteration}.png\")\n",
    "        save_image(x * 0.5 + 0.5, folder + f\"/input_{epoch}_{iteration}.png\")\n",
    "        if epoch == 1:\n",
    "            save_image(y * 0.5 + 0.5, folder + f\"/label_{epoch}_{iteration}.png\")\n",
    "    gen.train()\n",
    "\n",
    "    ##ADDITION\n",
    "    ypred = np.array(y_pred)\n",
    "    #print(ypred)\n",
    "    np.save(f\"ypred_{iteration}.npy\", ypred)\n",
    "    ##This addition saves the results as numpy arrays. Doing so, you can load them again and change the colors f.e.\n",
    "\n",
    "def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "    # If we don't do this then it will just have learning rate of old checkpoint\n",
    "    # and it will lead to many hours of debugging \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d886f13e-cbf4-4e2a-a521-50786bc1a9f1",
   "metadata": {},
   "source": [
    "### 3. Supersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a375b64-cdeb-4608-a29a-8c79c50dcfcb",
   "metadata": {},
   "source": [
    "### 3.1 Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6425e12b-cc5d-4594-98a8-f8f80dd9bd3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5d5e9e-e585-4516-84b1-058037ca865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Using device: cpu\n",
    "2.6.0\n",
    "<torch._C.Generator at 0x12fdc46f0>\n",
    "Index(['id', 'Building Height', 'Car Availability', 'Green Space',\n",
    "       'Population Density', 'Crime Rate', 'Road Casualties',\n",
    "       'Transportation Acessibility', 'Rating', 'Sentiment', 'Subtitle',\n",
    "       'Overlap'],\n",
    "      dtype='object')\n",
    "(250000, 4)\n",
    "(4, 500, 500)\n",
    "(250000, 2)\n",
    "(2, 500, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9a1ad0-c5ec-4d4a-817a-f22dc1449e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the process for labels \n",
    "\n",
    "# Transform to numpy\n",
    "data=np.array(df[['id','Subtitle']])\n",
    "print(data.shape)\n",
    "\n",
    "# Transpose to have first the channels\n",
    "data=np.transpose(data)\n",
    "\n",
    "# Reshape to (2,height,width)\n",
    "data= data.reshape(2,500,500)\n",
    "print(data.shape)\n",
    "\n",
    "# Divide into set\n",
    "ylabel=np.empty((0,1,256,256))\n",
    "\n",
    "for j in range(0,w-s,step):\n",
    "    for i in range(0,h-s,step):\n",
    "        # take slice from data of size [s x s] \n",
    "        sample = data[1:,i:i+s,j:j+s]\n",
    "        ylabel=np.append(ylabel,[sample],axis=0)\n",
    "\n",
    "# print(ylabel.shape)\n",
    "\n",
    "# Normalize\n",
    "ylabel[:,0,:,:] = ylabel[:,0,:,:]/np.max(ylabel[:,0,:,:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd4bc63-1f7e-40a2-abaa-16ec02b9298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_image(image, tile_size=256, stride=256):\n",
    "h, w = image.shape\n",
    "tiles = []\n",
    "positions = [] # record the position of each tile\n",
    "\n",
    "# make sure to cover the entire image, including the edges\n",
    "for i in range(0, h-tile_size+1, stride):\n",
    "for j in range(0, w-tile_size+1, stride):\n",
    "# extract tile\n",
    "tile = image[i:i+tile_size, j:j+tile_size]\n",
    "tiles.append(tile)\n",
    "positions.append((i, j))\n",
    "            \n",
    "    # Process the right edge\n",
    "    if w % tile_size != 0:\n",
    "        for i in range(0, h-tile_size+1, stride):\n",
    "            j = w - tile_size # Take the tile_size size from the right edge to the left\n",
    "            tile = image[i:i+tile_size, j:j+tile_size]\n",
    "            tiles.append(tile)\n",
    "            positions.append((i, j))\n",
    "    \n",
    "    # Process the bottom edge\n",
    "    if h % tile_size != 0:\n",
    "        for j in range(0, w-tile_size+1, stride):\n",
    "            i = h - tile_size # Take the tile_size size from the bottom edge upwards\n",
    "            tile = image[i:i+tile_size, j:j+tile_size]\n",
    "            tiles.append(tile)\n",
    "            positions.append((i, j))\n",
    "            \n",
    "    # Process the lower right corner\n",
    "    if h % tile_size != 0 and w % tile_size != 0:\n",
    "        tile = image[h-tile_size:h, w-tile_size:w]\n",
    "        tiles.append(tile)\n",
    "        positions.append((h-tile_size, w-tile_size))\n",
    "    \n",
    "    return np.array(tiles), positions\n",
    "\n",
    "# Use this function to process your data\n",
    "image_tiles, positions = split_image(df['id'].values.reshape(500, 500))\n",
    "\n",
    "# Make sure the data range is correct\n",
    "print(\"Original image size:\", df['id'].values.reshape(500, 500).shape)\n",
    "print(\"Number of tiles after splitting:\", len(image_tiles))\n",
    "print(\"Tile size:\", image_tiles[0].shape)\n",
    "\n",
    "# Check the range of the data\n",
    "print(\"Original data range:\", np.min(df['id'].values), \"-\", np.max(df['id'].values))\n",
    "print(\"Segmented data range:\", np.min(image_tiles), \"-\", np.max(image_tiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1634d00-1769-4611-9915-f597997f1db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Assuming dataclipNew is the normalized version of dataclip\n",
    "dataclipNew = dataclip.copy()\n",
    "\n",
    "# Normalize R\n",
    "dataclipNew[:, 0, :, :] = dataclipNew[:, 0, :, :] / np.max(dataclipNew[:, 0, :, :])\n",
    "\n",
    "# Normalize G\n",
    "dataclipNew[:, 1, :, :] = dataclipNew[:, 1, :, :] / np.max(dataclipNew[:, 1, :, :])\n",
    "\n",
    "# Normalize B\n",
    "dataclipNew[:, 2, :, :] = dataclipNew[:, 2, :, :] / np.max(dataclipNew[:, 2, :, :])\n",
    "\n",
    "# Assuming ylabelNew is a processed version of ylabel\n",
    "ylabelNew = ylabel.copy()\n",
    "\n",
    "# Reconstructing the whole image from data\n",
    "ylabelReconstruct = np.zeros((1, h, w))\n",
    "ylabelIterator = 0\n",
    "for j in range(0, w-s, step):\n",
    "    for i in range(0, h-s, step):\n",
    "        ylabelReconstruct[0, i:i+s, j:j+s] = ylabel[ylabelIterator, 0, :, :]\n",
    "        ylabelIterator += 1\n",
    "\n",
    "# Plot array as image with plt.imshow(array, cmap)\n",
    "# Gray is 0--255, RGB is 0-1\n",
    "i = 0\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(np.transpose(ylabelReconstruct[0, :, :]) * 255, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(np.transpose(ylabel[i, 0, :, :]) * 255, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(np.transpose(ylabelNew[i, 0, :, :]) * 255, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(np.transpose(dataclipNew[i, 0, :, :]), cmap=sns.color_palette(\"\", as_cmap=True))\n",
    "plt.show()\n",
    "\n",
    "# Check shape of X data train\n",
    "print(dataclipNew.shape)\n",
    "\n",
    "# Recreating 3 channels in total\n",
    "rgb = np.hstack((ylabelNew, ylabelNew, ylabelNew))\n",
    "print(rgb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa7918b-316e-48c0-800b-202d41664a85",
   "metadata": {},
   "source": [
    "### 3.2 Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d53f6ca-f6c4-405c-a365-df956a693c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "dft = pd.read_csv('/Users/Jun Hao/UCL/python/5_Pix2Pix/Test_2.csv')\n",
    "\n",
    "# print(dft.columns)\n",
    "\n",
    "# Transform to numpy\n",
    "datatest=np.array(dft[['id','Sentiment', 'Green Space', 'Transportation Acessibility']])\n",
    "# print(datatest.shape)\n",
    "\n",
    "datatest=np.transpose(datatest)\n",
    "\n",
    "datatest= datatest.reshape(4,300,300)\n",
    "# print(datatest.shape)\n",
    "\n",
    "# Divide into set\n",
    "w=300 #width\n",
    "h=300 #height\n",
    "s=256 #size\n",
    "step=200 #step\n",
    "\n",
    "datacliptest=np.empty((0,3,256,256))\n",
    "\n",
    "idvaltest=np.empty((0,256,256))\n",
    "\n",
    "for j in range(0,w-s,step):\n",
    "    for i in range(0,h-s,step):\n",
    "        #take slice from data of size [s x s] \n",
    "        sample = datatest[1:,i:i+s,j:j+s]\n",
    "        sampleID = datatest[0,i:i+s,j:j+s]\n",
    "\n",
    "        datacliptest=np.append(datacliptest,[sample],axis=0)\n",
    "        idvaltest=np.append(idvaltest,[sampleID],axis=0)\n",
    "\n",
    "\n",
    "# print(datacliptest.shape)\n",
    "    \n",
    "# Normalize the data\n",
    "\n",
    "# Normalize R\n",
    "datacliptest[:,0,:,:] = datacliptest[:,0,:,:]/np.max(datacliptest[:,0,:,:]) \n",
    "\n",
    "# Normalize G\n",
    "datacliptest[:,1,:,:] = datacliptest[:,1,:,:]/np.max(datacliptest[:,1,:,:]) \n",
    "\n",
    "# Normalize B\n",
    "datacliptest[:,2,:,:] = datacliptest[:,2,:,:]/np.max(datacliptest[:,2,:,:]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29b8ac3-55c9-400a-8820-95808ab9d533",
   "metadata": {},
   "source": [
    "### 3.3 Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c022efa5-a743-4575-96e5-5900b957aae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "disc = Discriminator(in_channels=3).to(DEVICE)\n",
    "gen = Generator(in_channels=3, features=64).to(DEVICE)\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999),)\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "BCE = nn.BCEWithLogitsLoss()\n",
    "L1_LOSS = nn.L1Loss()\n",
    "\n",
    "if LOAD_MODEL:\n",
    "   load_checkpoint(\n",
    "       CHECKPOINT_GEN, gen, opt_gen, LEARNING_RATE,\n",
    "   )\n",
    "   load_checkpoint(\n",
    "       CHECKPOINT_DISC, disc, opt_disc, LEARNING_RATE,\n",
    "   )\n",
    "   \n",
    "#Train the model\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "##ADDITION\n",
    "tensor_x = torch.Tensor(dataclipNew) # transform to torch tensor\n",
    "tensor_y = torch.Tensor(rgb)\n",
    "\n",
    "train_dataset = TensorDataset(tensor_x,tensor_y) # create your datset\n",
    "##\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=NUM_WORKERS,)\n",
    "\n",
    "g_scaler = torch.cuda.amp.GradScaler()\n",
    "d_scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "NUM_EPOCHS = 70\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print('epoch is',epoch)\n",
    "    train_fn(disc, gen, train_loader, opt_disc, opt_gen, L1_LOSS, BCE, g_scaler, d_scaler)\n",
    "    \n",
    "    if SAVE_MODEL and epoch % 5 == 0:\n",
    "        save_checkpoint(gen, opt_gen, filename = CHECKPOINT_GEN)\n",
    "        save_checkpoint(disc, opt_disc, filename = CHECKPOINT_DISC)\n",
    "\n",
    "## ADDITION\n",
    "save_checkpoint(gen, opt_gen, filename = CHECKPOINT_GEN)\n",
    "save_checkpoint(disc, opt_disc, filename = CHECKPOINT_DISC)\n",
    "##\n",
    "\n",
    "# Results: Ideally we need D_fake=0 and D_real=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6ab0ec-f567-43ca-b4d4-7c1c7edd2885",
   "metadata": {},
   "source": [
    "### 3.4 Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f79d782-462b-439b-99fa-2a1dbeded073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST each image individually\n",
    "for i in range(len(datacliptest)):\n",
    "    \n",
    "    tensor_x = torch.Tensor(datacliptest[i].reshape(1,3,256,256)) # transform to torch tensor\n",
    "    \n",
    "    #We can use a fake test target/ we only need it as placeholder\n",
    "    testRandomY = np.empty_like(datacliptest[i].reshape(1,3,256,256))\n",
    "    tensor_y = torch.Tensor(testRandomY)\n",
    "    \n",
    "    val_dataset = TensorDataset(tensor_x,tensor_y) # create your datset\n",
    "    \n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "    \n",
    "    save_some_examples(gen, val_loader, 52, folder=\"evaluation\", iteration=i) #Remember to choose the epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1fc86e-a3f7-4776-a7e4-16f132daf76f",
   "metadata": {},
   "source": [
    "### 3.5 Save the Results (csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13028a95-cc3b-41f0-82ab-45c01a8a14cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nSamples = len(datacliptest)\n",
    "yFull = np.zeros((nSamples, 3, 256, 256))\n",
    "\n",
    "for i in range(len(datacliptest)): \n",
    "    yFull[i] = np.load(f\"ypred_{i}.npy\")\n",
    "\n",
    "\n",
    "## Visualising the image\n",
    "# Reconstructing the whole image from the NN results\n",
    "yReconstruct = np.zeros((3, 300, 300))  # Adjusted to match the dimensions of the test data\n",
    "idReconstruct = np.zeros((300, 300))    # Adjusted to match the dimensions of the test data\n",
    "ylabelIterator = 0\n",
    "for j in range(0, 300-s, step):  # Adjusted to match the dimensions of the test data\n",
    "    for i in range(0, 300-s, step):  # Adjusted to match the dimensions of the test data\n",
    "        yReconstruct[:, i:i+s, j:j+s] = yFull[ylabelIterator, :, :, :]\n",
    "        idReconstruct[i:i+s, j:j+s] = idvaltest[ylabelIterator, :, :]\n",
    "        ylabelIterator += 1\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(np.transpose(yReconstruct, (1, 2, 0)), cmap='BrBG_r')\n",
    "plt.show()\n",
    "\n",
    "# Reshape multidimensional array to get it as list\n",
    "yReconstruct = yReconstruct.reshape(1, 3, -1)\n",
    "idReconstruct = idReconstruct.reshape(-1)\n",
    "\n",
    "# Construct a dataframe from the NN outputs and save as csv\n",
    "dfy = pd.DataFrame(idReconstruct[:], columns=['id'])\n",
    "dfy['ch1'] = yReconstruct[0, 0, :]\n",
    "dfy['ch2'] = yReconstruct[0, 1, :]\n",
    "dfy['ch3'] = yReconstruct[0, 2, :]\n",
    "dfy.to_csv(f'./_pred_LG_52.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
